{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77ef1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.10.2-cp36-cp36m-manylinux2014_aarch64.whl (53.5 MB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.11.3-cp36-cp36m-manylinux2014_aarch64.whl (14.7 MB)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv-python-headless-4.7.0.72.tar.gz (91.1 MB)\n",
      "     |################################| 91.1 MB 26 kB/s              \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
      "Collecting pillow!=8.3.0,>=5.3.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (3.0 MB)\n",
      "     |################################| 3.0 MB 15.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torchvision) (1.13.3)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2014_aarch64.whl (12.4 MB)\n",
      "     |################################| 12.4 MB 22.7 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: opencv-python-headless\n",
      "  Building wheel for opencv-python-headless (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opencv-python-headless: filename=opencv_python_headless-4.7.0.72-cp36-cp36m-linux_aarch64.whl size=13818751 sha256=5e97aae3c791091f8fd1aec9b921cd70b33fe224efef2e02f292775f93ebcdae\n",
      "  Stored in directory: /root/.cache/pip/wheels/c4/59/7b/7b791df4ddbaae4cf1911453089dd4205504dddd4437f942d9\n",
      "Successfully built opencv-python-headless\n",
      "Installing collected packages: torch, pillow, numpy, torchvision, opencv-python-headless\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 5.1.0\n",
      "    Uninstalling Pillow-5.1.0:\n",
      "      Successfully uninstalled Pillow-5.1.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.13.3\n",
      "    Uninstalling numpy-1.13.3:\n",
      "      Successfully uninstalled numpy-1.13.3\n",
      "Successfully installed numpy-1.19.5 opencv-python-headless-4.7.0.72 pillow-8.4.0 torch-1.10.2 torchvision-0.11.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085825d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import numpy as np\n",
    "#from rplidar import RPLidar\n",
    "#import torch\n",
    "#import torchvision.transforms as T\n",
    "##from torchvision.models import resnet50\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c08e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MIN_DISTANCE = 1000  # Minimum distance for object avoidance in mm\n",
    "\n",
    "# Initialize RPLidar\n",
    "lidar = RPLidar('/dev/ttyUSB0')  # Update with your RPLidar's port\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load pre-trained object detection model\n",
    "model = resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Function to get object detection results\n",
    "def detect_objects(image, model):\n",
    "    transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    return output\n",
    "\n",
    "# Function to process LIDAR data for object avoidance\n",
    "def process_lidar_data(lidar_data):\n",
    "    for angle, distance in lidar_data:\n",
    "        if distance < MIN_DISTANCE:\n",
    "            return True  # Object detected within the minimum distance\n",
    "    return False\n",
    "\n",
    "# Function to display LIDAR data as a simple plot\n",
    "def display_lidar_data(lidar_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    angle = [item[1] for item in lidar_data]\n",
    "    distance = [item[2] for item in lidar_data]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(angle, distance)\n",
    "    plt.xlabel('Angle [deg]')\n",
    "    plt.ylabel('Distance [mm]')\n",
    "    plt.title('LIDAR Data')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Function to show an image in Jupyter Notebook\n",
    "def show_image(image):\n",
    "    _, encoded_image = cv2.imencode('.jpg', image)\n",
    "    display(HTML(data=f'<img src=\"data:image/jpg;base64,{encoded_image.tobytes().decode(\"utf-8\")}\" alt=\"Webcam Image\"/>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b750a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Read image from webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform object identification\n",
    "        output = detect_objects(frame, model)\n",
    "        # You may want to process the output further to extract the detected objects and their labels\n",
    "\n",
    "        # Get LIDAR data\n",
    "        lidar_data = [item for item in lidar.iter_scans()]\n",
    "\n",
    "        # Perform object avoidance\n",
    "        if process_lidar_data(lidar_data):\n",
    "            print(\"Obstacle detected! Take necessary action.\")\n",
    "            # Insert your control code here to take necessary action when an obstacle is detected\n",
    "\n",
    "        # Display the webcam frame\n",
    "        clear_output(wait=True)\n",
    "        show_image(frame)\n",
    "\n",
    "        # Display the LIDAR data\n",
    "        display_lidar_data(lidar_data)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping...\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    lidar.stop()\n",
    "    lidar.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = 'output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize VideoWriter for raw video\n",
    "raw_video_out = cv2.VideoWriter(os.path.join(output_dir, 'raw_video.avi'), cv2.VideoWriter_fourcc(*'XVID'), 20, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Initialize VideoWriter for detection video\n",
    "detection_video_out = cv2.VideoWriter(os.path.join(output_dir, 'detection_video.avi'), cv2.VideoWriter_fourcc(*'XVID'), 20, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Function to draw LIDAR data overlay on the frame\n",
    "def draw_lidar_overlay(frame, lidar_data):\n",
    "    overlay_frame = frame.copy()\n",
    "    for angle, distance in lidar_data:\n",
    "        x = int(frame.shape[1]/2 + distance * np.cos(np.radians(angle)))\n",
    "        y = int(frame.shape[0]/2 - distance * np.sin(np.radians(angle)))\n",
    "        cv2.circle(overlay_frame, (x, y), 2, (0, 255, 0), -1)\n",
    "    return overlay_frame\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read image from webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Perform object identification\n",
    "        output = detect_objects(frame, model)\n",
    "        # You may want to process the output further to extract the detected objects and their labels\n",
    "\n",
    "        # Get LIDAR data\n",
    "        lidar_data = [item for item in lidar.iter_scans()]\n",
    "\n",
    "        # Perform object avoidance\n",
    "        if process_lidar_data(lidar_data):\n",
    "            print(\"Obstacle detected! Take necessary action.\")\n",
    "            # Insert your control code here to take necessary action when an obstacle is detected\n",
    "\n",
    "        # Save raw video frame\n",
    "        raw_video_out.write(frame)\n",
    "\n",
    "        # Draw LIDAR overlay on the frame\n",
    "        lidar_overlay_frame = draw_lidar_overlay(frame, lidar_data)\n",
    "\n",
    "        # Save detection video frame\n",
    "        detection_video_out.write(lidar_overlay_frame)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping...\")\n",
    "finally:\n",
    "    cap.release()\n",
    "    raw_video_out.release()\n",
    "    detection_video_out.release()\n",
    "    lidar.stop()\n",
    "    lidar.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
